{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa71f1f8-a39a-47e6-b964-652a82eba1c8",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning \n",
    "algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07b3461-7b2b-4d08-b9cb-fa79e2fafa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's the relationship between polynomial functions and kernel functions:\n",
    "\n",
    "#Kernel Functions:\n",
    "\n",
    "#Kernel functions are mathematical functions that compute the similarity or inner product between data points in the input feature space.\n",
    "#They allow machine learning algorithms to work with data in higher-dimensional spaces without explicitly transforming the data.\n",
    "#Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid kernels.\n",
    "#Polynomial Kernel:\n",
    "\n",
    "#The polynomial kernel is a specific type of kernel function.\n",
    "#It calculates the similarity between data points as a polynomial function of the dot product of the original feature vectors.\n",
    "\n",
    "#Use in SVM and Kernelized Algorithms:\n",
    "\n",
    "#Polynomial kernels are often used in kernelized machine learning algorithms, such as Support Vector Machines (SVMs), to capture non-linear relationships in data.\n",
    "#SVMs with polynomial kernels can find decision boundaries that are polynomial functions of the input features without explicitly transforming the data into a \n",
    "# higher-dimensional space.\n",
    "#Degree Parameter:\n",
    "\n",
    "#In polynomial kernels, the 'd' parameter controls the degree of the polynomial. A larger 'd' leads to higher-dimensional polynomial functions.\n",
    "#Higher-degree polynomials can capture more complex non-linear relationships but may also be more prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e830f89-24e9-4db8-8d60-86205b321505",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136abffc-d326-4ec5-8bf0-7b4e80bee680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "poly_svm = SVC(kernel='poly', degree=3, C=1.0)  \n",
    "poly_svm.fit(X_train, y_train)\n",
    "y_pred = poly_svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93554397-403d-4904-ac89-c408f173c88d",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d0427f-0bb6-41d5-abea-ee255b515d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small Epsilon (ε):\n",
    "\n",
    "# When epsilon is set to a very small value, such as close to zero, the margin of tolerance around the predicted values is extremely narrow.\n",
    "# In this case, the SVR model aims to fit the training data as closely as possible, even if it means allowing more training points to be within the margin of error.\n",
    "# Consequently, a smaller epsilon tends to result in a larger number of support vectors because the model is less tolerant of errors and tries to fit the training data \n",
    "#points precisely.\n",
    "# Large Epsilon (ε):\n",
    "\n",
    "# Conversely, when epsilon is set to a larger value, the margin of tolerance becomes wider.\n",
    "##With a wider margin of tolerance, the SVR model allows more data points to be outside the margin without incurring a penalty.\n",
    "#As a result, a larger epsilon tends to result in fewer support vectors because the model is more tolerant of errors, and it does not require as many data points to be \n",
    "# within the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea79b67-f3ee-4afd-9aac-bb51a4f996e4",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter \n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works \n",
    "and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec6f4af-420c-4890-a039-082edac57bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel Function:\n",
    "\n",
    "#Purpose: The kernel function determines the type of mapping used to transform the data into a higher-dimensional space. It plays a crucial role in capturing complex \n",
    "# relationships in the data.\n",
    "#Examples:\n",
    "#Linear Kernel (kernel='linear'): Suitable for linear relationships when you believe the data is separable by a hyperplane.\n",
    "#Radial Basis Function (RBF) Kernel (kernel='rbf'): Suitable for non-linear relationships when you have no prior knowledge of the data's distribution.\n",
    "#Polynomial Kernel (kernel='poly'): Suitable for polynomial relationships when you have a prior belief that the data follows a polynomial pattern.\n",
    "#C Parameter:\n",
    "\n",
    "#Purpose: The C parameter controls the trade-off between minimizing the training error and maximizing the margin of tolerance (epsilon). A smaller C allows for a larger \n",
    "# margin but allows some training points to violate the margin, while a larger C penalizes such violations and results in a smaller margin.\n",
    "#Examples:\n",
    "#Increase C when you want to fit the training data more closely and prioritize accuracy.\n",
    "#Decrease C when you want a larger margin and a more robust model that generalizes better to unseen data.\n",
    "#Epsilon Parameter (ε):\n",
    "\n",
    "#Purpose: Epsilon defines the margin of tolerance within which no penalty is associated with errors. It determines how much deviation from the predicted values is acceptable.\n",
    "#Examples:\n",
    "#Increase ε when you want to allow larger deviations from the predicted values, making the model more tolerant of errors and less sensitive to outliers.\n",
    "#Decrease ε when you want the model to be less tolerant of errors and require predictions to be closer to the training data points.\n",
    "#Gamma Parameter (γ):\n",
    "\n",
    "#Purpose: The gamma parameter influences the shape of the decision boundary. A small gamma results in a broader decision boundary, while a large gamma leads to a more \n",
    "# complex, tightly fitted decision boundary.\n",
    "#Examples:\n",
    "#Increase γ when you have a strong belief that the decision boundary should be complex and tightly fitted to the training data.#Decrease γ when you want a smoother, \n",
    "# more generalizable decision boundary and wish to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32622a86-936a-4ad4-8249-524753749afc",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "        \n",
    "        Import the necessary libraries and load the dataseg\n",
    "        Split the dataset into training and testing setZ\n",
    "         Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "        Create an instance of the SVC classifier and train it on the training datW\n",
    "        hse the trained classifier to predict the labels of the testing datW\n",
    "         Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, \n",
    "\n",
    "        precision, recall, F1-scoreK\n",
    "         Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to \n",
    "        improve its performanc_\n",
    "        Train the tuned classifier on the entire dataseg\n",
    "        Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad174b82-2495-4998-b42f-9b6903a75bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_svc_classifier.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 1, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_svc = grid_search.best_estimator_\n",
    "best_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "joblib.dump(best_svc, 'best_svc_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76949721-0df3-4458-8ea5-a24de2569146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
