{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8639d4b1-e9f3-4758-83ec-47132ee918e4",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact \n",
    "the validity of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a572a739-86e8-4796-952b-cd3f1267b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA (Analysis of Variance) is a statistical technique used to compare the means of two or more groups. However, to obtain valid and reliable results \n",
    "# from ANOVA, certain assumptions need to be met. Violating these assumptions can lead to misleading or incorrect conclusions. \n",
    "\n",
    "# The main assumptions for ANOVA are as follows:\n",
    "\n",
    "# Independence of Observations: The observations in each group are assumed to be independent of each other. This means that the data points within \n",
    "# each group should not be influenced by or related to each other.\n",
    "\n",
    "# Normality: The data within each group should follow a normal distribution. ANOVA is robust to mild departures from normality, especially when sample\n",
    "# sizes are large. However, severe departures from normality can affect the validity of the results.\n",
    "\n",
    "# Homogeneity of Variance: The variance of the data in each group should be approximately equal. Homogeneity of variance means that the spread of data\n",
    "# points should be similar across all groups. If the variances are unequal, it can lead to a loss of power and result in Type I or Type II errors.\n",
    "\n",
    "# Examples of Violations and Their Impact on ANOVA:\n",
    "\n",
    "# Non-Independence: In a study involving multiple measurements from the same subject, such as repeated measures ANOVA, the independence assumption may be\n",
    "# violated. For example, in a study where the same group of participants is tested at different time points, the observations within each participant may be correlated.\n",
    "\n",
    "# Non-Normality: If the data within each group deviates significantly from a normal distribution, it may impact the accuracy of p-values and confidence intervals. \n",
    "# For instance, if the data is heavily skewed or contains extreme outliers, ANOVA results may not be valid.\n",
    "\n",
    "# Heterogeneity of Variance: Unequal variance across groups can lead to inflated or deflated F-statistics, affecting the interpretation of significance levels.\n",
    "# For instance, if one group has much larger variance than the others, the overall ANOVA test may become sensitive to that group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2112a-2c8c-467b-91d7-894d4760eb84",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8eb08e-d089-4de5-84be-469a4101f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Way ANOVA:\n",
    "# One-Way ANOVA is used when we want to compare the means of three or more independent groups (levels) with a single categorical independent variable.\n",
    "# The categorical variable should have at least three levels. It helps determine if there are any significant differences among the means of the groups.\n",
    "# For example, it can be used to compare the performance of students from different schools or the effectiveness of different drug treatments.\n",
    "\n",
    "## Two-Way ANOVA:\n",
    "# Two-Way ANOVA is used when we have two categorical independent variables and want to analyze their combined effects on a continuous dependent variable. \n",
    "# It allows us to investigate main effects (the effect of each independent variable individually) as well as the interaction effect (the joint effect of both \n",
    "# independent variables). For example, in a study of the effects of a new drug treatment, we might want to investigate the main effects of dosage and gender, \n",
    "# as well as the interaction between dosage and gender.\n",
    "\n",
    "## Repeated Measures ANOVA:\n",
    "# Repeated Measures ANOVA is used when we have a single group of subjects measured at multiple time points or under different conditions.\n",
    "# It allows us to analyze within-subjects effects over time or conditions. This design is commonly used in longitudinal studies or experiments where the\n",
    "# same subjects are measured under various conditions. For example, in a study on the effect of cognitive training, the same group of participants might \n",
    "# be tested before training, after one week of training, and after one month of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41410705-461c-453b-a3a9-38baf3a6a95e",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45187e13-4b77-4f44-bb32-15a912592a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The partitioning of variance in ANOVA refers to the decomposition of the total variation observed in the data into different components that can be attributed\n",
    "# to specific sources of variation. These components include the between-group variance and the within-group variance. Understanding this concept is crucial\n",
    "# because it allows researchers to determine the relative contributions of different factors to the total variation in the data. \n",
    "\n",
    "# The partitioning of variance is important for the following reasons:\n",
    "\n",
    "# Identifying Significant Effects: By comparing the between-group variance with the within-group variance, ANOVA helps determine if there are any significant\n",
    "# differences among the group means. If the between-group variance is much larger than the within-group variance, it suggests that there are significant differences \n",
    "# between the groups.\n",
    "\n",
    "# Assessing the Magnitude of Effects: Understanding the partitioning of variance allows researchers to assess the magnitude of the effects of the independent\n",
    "# variable(s) on the dependent variable. Larger between-group variance relative to the within-group variance indicates stronger effects.\n",
    "\n",
    "# Design and Experimental Planning: Partitioning variance helps in experimental design and planning. Researchers can focus on factors that contribute the most \n",
    "# to the overall variation, allowing them to design more efficient experiments and allocate resources more effectively.\n",
    "\n",
    "# Interpreting Results: Knowing the partitioning of variance helps in interpreting the results of the ANOVA analysis. Researchers can explain how much of the \n",
    "# variation is due to group differences and how much is due to individual variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0f029-d363-4158-bdd6-3ae727e2f296",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual \n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10fcd615-a23e-41ec-bdb2-269a92c18528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 1072.9333333333334\n",
      "Explained Sum of Squares (SSE): 1002.1333333333334\n",
      "Residual Sum of Squares (SSR): 70.79999999999995\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "group1 = [10, 12, 15, 8, 11]\n",
    "group2 = [20, 18, 22, 19, 23]\n",
    "group3 = [30, 35, 32, 28, 31]\n",
    "\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "overall_mean = np.mean(all_data)\n",
    "sst = np.sum((all_data - overall_mean) ** 2)\n",
    "group_means = [np.mean(group1), np.mean(group2), np.mean(group3)]\n",
    "sse = np.sum((group_means - overall_mean) ** 2) * len(group1)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17d460-8a6c-470f-984f-1f903d8478cb",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1129c5f2-efda-4b0a-8d7d-5e3f3b835450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect for GroupA: 1724.9452269170602\n",
      "Main Effect for GroupB: 2.4781103987525217\n",
      "Interaction Effect: 177.5667832633544\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = {'GroupA': [10, 12, 15, 8, 11, 20, 18, 22, 19, 23],\n",
    "        'GroupB': [30, 35, 32, 28, 31, 40, 38, 42, 39, 43],\n",
    "        'Outcome': [60, 70, 80, 50, 65, 85, 90, 75, 95, 100]}\n",
    "df = pd.DataFrame(data)\n",
    "model = ols('Outcome ~ GroupA + GroupB + GroupA:GroupB', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "main_effect_groupA = anova_table.loc['GroupA', 'sum_sq']\n",
    "main_effect_groupB = anova_table.loc['GroupB', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['GroupA:GroupB', 'sum_sq']\n",
    "\n",
    "print(\"Main Effect for GroupA:\", main_effect_groupA)\n",
    "print(\"Main Effect for GroupB:\", main_effect_groupB)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94deb3d2-9160-4dab-88b2-20e901121fc5",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. \n",
    "What can you conclude about the differences between the groups, and how would you interpret these \n",
    "results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ad9399-41b6-4721-b7f2-4fdd4a1c2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a one-way ANOVA, the F-statistic measures the ratio of the variance between the groups to the variance within the groups. The p-value associated with \n",
    "# the F-statistic indicates the probability of observing such an extreme F-statistic by chance alone, assuming that the null hypothesis is true \n",
    "\n",
    "# Given the F-statistic of 5.23 and a p-value of 0.02, we can make the following conclusions:\n",
    "\n",
    "# Statistical Significance:\n",
    "# The p-value (0.02) is less than the significance level (usually denoted by alpha) typically set at 0.05. This means that there is sufficient evidence to \n",
    "# reject the null hypothesis, suggesting that there are significant differences between at least two of the groups.\n",
    "\n",
    "# Group Differences:\n",
    "# The F-statistic of 5.23 indicates that the variation between the group means is greater than the variation within the groups. This suggests that there are \n",
    "# differences in the means of at least some of the groups. However, the F-statistic does not provide information about which specific groups differ from each other.\n",
    "\n",
    "# Further Analysis:\n",
    "# Since the one-way ANOVA test indicates significant differences among the groups, it is appropriate to perform post hoc tests (e.g., Tukey's HSD, Bonferroni,\n",
    "# or Dunnett's test) to determine which specific groups differ significantly from each other. These post hoc tests will help identify the pairwise comparisons that\n",
    "# contribute to the significant F-statistic.\n",
    "\n",
    "# Practical Significance:\n",
    "# While the results may be statistically significant, it is essential to consider the practical significance of the group differences. A significant difference \n",
    "# does not always imply a large or meaningful effect size. Evaluating the effect size will provide insight into the magnitude of the differences among the groups\n",
    "# and their practical relevance.\n",
    "\n",
    "# In summary, with an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there are significant differences between at least some of the groups.\n",
    "# However, further post hoc tests and consideration of effect sizes are necessary to determine the specific group differences and their practical implications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314585c4-1b62-42c7-b85d-56b57a4b9890",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential \n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01596b36-0784-4105-881f-9587486dc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data in a repeated measures ANOVA is essential to obtain valid and reliable results. The approach you choose to handle missing data can \n",
    "# have significant consequences on the validity of your analysis and the interpretation of the results. Here are some common methods for handling missing data \n",
    "# in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "# Complete Case Analysis (Listwise Deletion):\n",
    "# In this method, any participant with missing data on any variable is excluded from the analysis. While it is straightforward, it can lead to a loss of \n",
    "# valuable information and reduced statistical power, especially if the missing data are not missing completely at random (MCAR). If data are missing not at random \n",
    "# (MNAR) or missing at random (MAR), this method can introduce bias and make the analysis less representative of the entire sample.\n",
    "\n",
    "# Mean Imputation:\n",
    "# Mean imputation involves replacing missing values with the mean of the observed values for that variable. This method can artificially reduce variability and\n",
    "# underestimate standard errors, leading to an inflated Type I error rate. It also does not account for uncertainty in the imputed values, which can lead to \n",
    "# biased estimates and invalid standard errors.\n",
    "\n",
    "# Last Observation Carried Forward (LOCF) or Next Observation Carried Backward (NOCB):\n",
    "# LOCF involves using the last observed value to replace missing data, while NOCB uses the next observed value. These methods can introduce bias if there is a \n",
    "# trend in the data over time or if missing values are related to treatment response. They may not be suitable for repeated measures ANOVA if there is no reasonable\n",
    "# assumption that missing data remain constant between measurement points.\n",
    "\n",
    "# Multiple Imputation:\n",
    "# Multiple imputation involves creating multiple plausible imputations for each missing value, incorporating uncertainty in the imputed values.\n",
    "# The analysis is performed on each imputed dataset separately, and the results are combined to obtain unbiased estimates and valid standard errors. \n",
    "# Multiple imputation can be computationally intensive but is considered a robust and statistically valid approach to handle missing data.\n",
    "\n",
    "# Mixed-Effects Models (Longitudinal Data Analysis):\n",
    "# Mixed-effects models (also known as hierarchical linear models or random-effects models) can handle missing data naturally within the framework of the analysis.\n",
    "# These models use all available data, including data from participants with missing data, and account for individual-level variability, which helps to reduce the\n",
    "# impact of missing data on the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567dca6-4d23-4c6a-b646-2646fb4f177e",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide \n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c4d9d3-58d5-41f8-80f2-e40c33330f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After obtaining a significant result from ANOVA (Analysis of Variance), post-hoc tests are used to compare specific pairs of groups to determine which groups\n",
    "# differ significantly from each other. Post-hoc tests are necessary when ANOVA indicates that there are overall group differences, but it does not specify which\n",
    "# specific groups are different from each other. Some common post-hoc tests include:\n",
    "\n",
    "# Tukey's Honestly Significant Difference (HSD) Test:\n",
    "# Tukey's HSD test is commonly used when the sample sizes are equal across all groups. It controls the familywise error rate, making it suitable for multiple\n",
    "# pairwise comparisons. Tukey's HSD test is often used when you have a balanced design with a moderate to large number of groups.\n",
    "\n",
    "# Bonferroni Correction:\n",
    "# Bonferroni correction is a conservative method that adjusts the significance level for each individual comparison. It divides the desired alpha level by the \n",
    "# number of comparisons being made to control the familywise error rate. It is suitable for situations where the number of pairwise comparisons is relatively small.\n",
    "\n",
    "# Scheffe's Method:\n",
    "# Scheffe's method is a more liberal approach that is used when the number of comparisons is large or when the sample sizes are unequal. It offers robust control\n",
    "# of the familywise error rate but may have wider confidence intervals compared to Tukey's HSD or Bonferroni correction.\n",
    "\n",
    "# Dunn's Test (for Nonparametric Data):\n",
    "# If the data do not meet the assumptions of normality or homogeneity of variance, nonparametric post-hoc tests like Dunn's test can be used. Dunn's test is \n",
    "# suitable for situations where the data are ranked or ordinal.\n",
    "\n",
    "# Example Situation:\n",
    "# Suppose you conducted a study to compare the effectiveness of four different treatment methods (A, B, C, and D) for pain relief. You collected pain intensity\n",
    "# scores from participants in each treatment group. After performing one-way ANOVA, you find that there is a significant difference among the four \n",
    "# treatment groups (p < 0.05).\n",
    "\n",
    "# Now, you want to determine which specific treatment groups differ significantly from each other. To do this, you would use a post-hoc test such as Tukey's HSD,\n",
    "# Bonferroni correction, or Scheffe's method. These post-hoc tests would allow you to make pairwise comparisons between the treatment groups and identify which \n",
    "#treatments are significantly different in terms of pain relief.\n",
    "\n",
    "# For example, you might find that Treatment A and Treatment B have significantly higher pain relief scores compared to Treatment C and Treatment D. \n",
    "# However, there may be no significant difference between Treatment A and Treatment B. The post-hoc test provides the necessary information to \n",
    "# interpret the differences between the groups and make more detailed comparisons beyond the overall ANOVA result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf03665-c6da-43c6-946f-afaf1931212d",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from \n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python \n",
    "to determine if there are any significant differences between the mean weight loss of the three diets. \n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ecd367-cdb0-434e-9e1c-86bd3264ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 34.35319172893017\n",
      "P-value: 5.382392031934751e-13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "diet_A = [2, 3, 4, 3, 5, 4, 6, 3, 4, 5, 3, 2, 4, 5, 3, 4, 5, 4, 6, 3, 4, 5, 6, 4, 3, 5, 6, 4, 3, 2, 4, 3, 5, 6, 5, 4, 3, 2, 4, 3, 5, 4, 3, 2, 4, 3, 5, 6, 4, 3]\n",
    "diet_B = [3, 4, 5, 4, 6, 5, 7, 4, 5, 6, 4, 3, 5, 6, 4, 5, 6, 5, 7, 4, 5, 6, 7, 5, 4, 6, 7, 5, 4, 3, 5, 4, 6, 7, 6, 5, 4, 3, 5, 4, 6, 5, 4, 3, 5, 4, 3, 5, 6, 5, 4]\n",
    "diet_C = [4, 5, 6, 5, 7, 6, 8, 5, 6, 7, 5, 4, 6, 7, 5, 6, 7, 6, 8, 5, 6, 7, 8, 6, 5, 7, 8, 6, 5, 4, 6, 5, 7, 8, 7, 6, 5, 4, 6, 5, 7, 6, 5, 4, 6, 5, 4, 6, 7, 6, 5]\n",
    "\n",
    "all_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "groups = ['Diet A'] * len(diet_A) + ['Diet B'] * len(diet_B) + ['Diet C'] * len(diet_C)\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee88c3e-8e46-44bf-9a41-797b1eeea12e",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to \n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They \n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to \n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or \n",
    "interaction effects between the software programs and employee experience level (novice vs. \n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0bd30-950e-416d-89c9-9fd2e6c37d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09833331-b8a5-4d48-96ae-ea8d97f7c283",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test \n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the \n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a \n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores \n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which \n",
    "group(s) differ significantly from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27167d33-0517-4775-9f52-0941a464a4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "T-Statistic: -11.856700966043\n",
      "P-Value: 3.8870232625941334e-17\n",
      "\n",
      "Tukey's HSD Post-Hoc Test Results:\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "    group1          group2       meandiff p-adj lower   upper  reject\n",
      "---------------------------------------------------------------------\n",
      "Control Group Experimental Group   8.5667   0.0 7.1204 10.0129   True\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "control_group_scores = [75, 78, 80, 82, 70, 72, 77, 76, 79, 74, 73, 75, 80, 71, 75, 76, 79, 82, 78, 81, 75, 79, 77, 78, 80, 76, 74, 78, 72, 79]\n",
    "experimental_group_scores = [85, 82, 84, 88, 83, 86, 87, 89, 81, 84, 85, 83, 82, 86, 87, 88, 85, 82, 86, 87, 83, 89, 84, 83, 87, 86, 85, 84, 88, 89]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    group_labels = ['Control Group'] * len(control_group_scores) + ['Experimental Group'] * len(experimental_group_scores)\n",
    "\n",
    "    tukey_results = pairwise_tukeyhsd(all_scores, group_labels)\n",
    "\n",
    "    print(\"\\nTukey's HSD Post-Hoc Test Results:\")\n",
    "    print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1a016-797c-4e5d-8271-5d96dc7e098f",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three \n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store \n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any \n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post\u0002hoc test to determine which store(s) differ significantly from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b2ceb57-4a20-488f-a7ae-408038d53ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA Results:\n",
      "F-Statistic: 63.04010695187157\n",
      "P-Value: 1.1952578128754204e-17\n",
      "\n",
      "Tukey's HSD Post-Hoc Test Results:\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1  group2 meandiff p-adj  lower    upper  reject\n",
      "------------------------------------------------------\n",
      "Store A Store B    -18.0   0.0 -26.0734 -9.9266   True\n",
      "Store A Store C     20.0   0.0  11.9266 28.0734   True\n",
      "Store B Store C     38.0   0.0  29.9266 46.0734   True\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "store_a_sales = [100, 120, 130, 110, 90, 100, 80, 140, 130, 120, 110, 95, 105, 125, 115, 135, 115, 125, 105, 100, 110, 115, 105, 120, 110, 90, 100, 105, 115, 120]\n",
    "store_b_sales = [85, 95, 105, 90, 75, 85, 65, 110, 100, 95, 90, 80, 90, 105, 100, 115, 100, 105, 90, 85, 90, 100, 90, 105, 95, 75, 85, 90, 100, 105]\n",
    "store_c_sales = [120, 140, 150, 130, 110, 120, 100, 160, 150, 140, 130, 115, 125, 145, 135, 155, 135, 145, 125, 120, 130, 135, 125, 140, 130, 110, 120, 125, 135, 140]\n",
    "\n",
    "data = pd.DataFrame({'Sales': store_a_sales + store_b_sales + store_c_sales,\n",
    "                     'Store': ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30})\n",
    "\n",
    "model = ols('Sales ~ C(Store)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "F_statistic = anova_table.loc['C(Store)', 'F']\n",
    "p_value = anova_table.loc['C(Store)', 'PR(>F)']\n",
    "\n",
    "print(\"One-Way ANOVA Results:\")\n",
    "print(\"F-Statistic:\", F_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    tukey_results = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "\n",
    "    print(\"\\nTukey's HSD Post-Hoc Test Results:\")\n",
    "    print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8114dd-851f-47e6-8a99-fc9f323860d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
