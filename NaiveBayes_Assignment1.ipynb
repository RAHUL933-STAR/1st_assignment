{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8936500e-d563-498c-8cba-8441e5cc3eb5",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabfad8e-4943-451d-804d-f7aeebd80e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes' theorem is a fundamental concept in probability theory and statistics named after the 18th-century statistician and philosopher Thomas Bayes. It provides a way to \n",
    "#update our beliefs or probabilities about an event based on new evidence or information. The theorem describes the relationship between the conditional probability of an\n",
    "# event A given an event B and the conditional probability of event B given event A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea1876-3d14-4f0d-8213-ec545abff02f",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402af729-f76c-47e2-bf3c-040b68f7791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes' theorem is represented by the following formula:\n",
    "#P(A∣B)= P(B∣A)⋅P(A) / P(B)\n",
    "\n",
    "#In this formula:\n",
    "#P(A∣B) represents the conditional probability of event A occurring given that event B has occurred.\n",
    "##P(B∣A) represents the conditional probability of event B occurring given that event A has occurred.\n",
    "#P(A) is the prior probability of event A, which is the probability of event A occurring without considering any new evidence.\n",
    "#P(B) is the prior probability of event B, which is the probability of event B occurring without considering any new evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af65798-9a65-4896-9927-2255d0167ea0",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0942b05b-73eb-48bb-b492-6a7e0ce93e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are some common ways in which Bayes' theorem is applied:\n",
    "\n",
    "#Medical Diagnosis: Bayes' theorem is used in medical diagnosis to update the probability of a patient having a particular disease based on the results of diagnostic tests.\n",
    "#It helps doctors make more informed decisions by considering both the prior probability of the disease and the test's accuracy.\n",
    "\n",
    "#Spam Detection: In email spam filters, Bayes' theorem is employed to classify incoming emails as either spam or not spam. It calculates the probability that an email is \n",
    "#spam based on the presence of certain words or features in the email.\n",
    "\n",
    "#Machine Learning: In machine learning, specifically in Bayesian machine learning, Bayes' theorem is used for probabilistic modeling. Bayesian methods are applied for tasks \n",
    "#like classification, regression, and parameter estimation, where uncertainty in model parameters or predictions is a concern.\n",
    "\n",
    "#Natural Language Processing: Bayes' theorem is used in natural language processing tasks such as text classification, sentiment analysis, and language modeling. It helps \n",
    "#in estimating the probability of a particular word or phrase given the context of a sentence.\n",
    "\n",
    "#Finance and Risk Management: In finance, Bayes' theorem is used for risk assessment and portfolio optimization. It helps investors update their beliefs about asset returns \n",
    "#based on new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10de17ea-8a11-4271-b0c4-0be3919dc9f9",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d89516e-e3fd-4919-b764-c7f275c87253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' Theorem Involves Conditional Probability: Bayes' theorem calculates the conditional probability of event A (or hypothesis A) given evidence B. In other words, \n",
    "#it computes P(A∣B), which is the probability of event A occurring given that evidence or event B has occurred.\n",
    "#Expressing Bayes' Theorem in Terms of Conditional Probability: Bayes' theorem can be expressed in terms of conditional probabilities as follows:\n",
    "#P(A∣B)= P(B∣A)⋅P(A) / P(B)\n",
    "#P(A∣B) is the conditional probability of A given B.\n",
    "#P(A) is the prior probability of A, representing our belief in A before considering any new evidence.\n",
    "#P(B) is the prior probability of B, representing the probability of observing the evidence B without considering any hypothesis.\n",
    "#Bayesian Inference: Bayes' theorem is a fundamental tool in Bayesian inference, a statistical approach that involves updating probabilities or beliefs about hypotheses \n",
    "#based on new evidence. It allows us to revise our beliefs (represented by \n",
    "#P(A)) in light of observed data (represented by P(B∣A) and P(B))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac7695-e3a9-4555-ac37-726f007f1ba1",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c65ccff-cf3a-4e4a-8c7e-bba12555f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's how you can decide which one to use:\n",
    "\n",
    "#Gaussian Naive Bayes:\n",
    "\n",
    "#Data Type: Gaussian Naive Bayes is suitable for continuous or numeric data, where the features can be modeled as following a Gaussian (normal) distribution.\n",
    "#Examples: It's often used in problems involving real-valued features like measurements of height, weight, temperature, etc.\n",
    "#Assumption: Assumes that each feature follows a Gaussian distribution with a mean and variance specific to each class.\n",
    "#Multinomial Naive Bayes:\n",
    "\n",
    "#Data Type: Multinomial Naive Bayes is appropriate for discrete data, especially when dealing with text data or categorical features.\n",
    "#Examples: It's commonly used for text classification, document classification, and sentiment analysis, where features represent word counts or term frequencies.\n",
    "#Assumption: Assumes that features are counts of occurrences of various categories (hence \"multinomial\").\n",
    "#Bernoulli Naive Bayes:\n",
    "\n",
    "#Data Type: Bernoulli Naive Bayes is suitable for binary or Boolean data, where features represent binary decisions (e.g., presence or absence of a feature).\n",
    "#Examples: It's often used in text classification when features are binary indicators like the presence or absence of certain words in a document.\n",
    "#Assumption: Assumes that features are generated by a set of independent Bernoulli trials (hence \"Bernoulli\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbb7b4-1254-4bc6-beef-cfad9ccefbdb",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "        \n",
    "        You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive \n",
    "        Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of \n",
    "        each feature value for each class:\n",
    "\n",
    "    Class\t X1=1 X1=2 \tX1=3 \tX2=1 \tX2=2 \tX2=3\t X2=4\n",
    "\n",
    "     A\t 3\t 3\t 4\t 4\t 3\t 3\t 3\n",
    "\n",
    "     B\t 2\t 2\t 1\t 2\t 2\t 2\t 3\n",
    "\n",
    "    Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance \n",
    "    to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfdb3a5-cbb0-428c-b07f-6484333c77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Bayes classifier predicts that the new instance belongs to Class A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Class': ['A', 'B'],\n",
    "    'X1=1': [3, 2],\n",
    "    'X1=2': [3, 2],\n",
    "    'X1=3': [4, 1],\n",
    "    'X2=1': [4, 2],\n",
    "    'X2=2': [3, 2],\n",
    "    'X2=3': [3, 2],\n",
    "    'X2=4': [3, 3],\n",
    "}\n",
    "\n",
    "new_instance = {'X1': 3, 'X2': 4}\n",
    "\n",
    "prior_A = 0.5\n",
    "prior_B = 0.5\n",
    "\n",
    "P_X1_3 = (data['X1=3'][0] + data['X1=3'][1]) / (sum(data['X1=1']) + sum(data['X1=2']) + sum(data['X1=3']))\n",
    "P_X2_4 = (data['X2=4'][0] + data['X2=4'][1]) / (sum(data['X2=1']) + sum(data['X2=2']) + sum(data['X2=3']) + sum(data['X2=4']))\n",
    "\n",
    "P_X1_3_given_A = data['X1=3'][0] / sum(data['X1=3'])\n",
    "P_X2_4_given_A = data['X2=4'][0] / sum(data['X2=4'])\n",
    "\n",
    "P_X1_3_given_B = data['X1=3'][1] / sum(data['X1=3'])\n",
    "P_X2_4_given_B = data['X2=4'][1] / sum(data['X2=4'])\n",
    "\n",
    "posterior_A = prior_A * P_X1_3_given_A * P_X2_4_given_A\n",
    "posterior_B = prior_B * P_X1_3_given_B * P_X2_4_given_B\n",
    "\n",
    "if posterior_A > posterior_B:\n",
    "    prediction = 'A'\n",
    "else:\n",
    "    prediction = 'B'\n",
    "\n",
    "print(f\"The Naive Bayes classifier predicts that the new instance belongs to Class {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654944b9-dba7-4bb9-baf8-08be5bf94450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
